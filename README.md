# Regularised-Least-Squares-using-LOOCV
<img src="https://cloud.githubusercontent.com/assets/16852003/20930056/75a20946-bbcc-11e6-9ff1-2a9440c66c67.png" width="60%"></img>
</br>
On the left image we see that the best lambda is 0. When lambda is 0, it is the same as performing Linear regression (non-regularised).
</br>
<img src="https://cloud.githubusercontent.com/assets/16852003/20928079/739145a2-bbc4-11e6-803e-1e9abaefa288.png" width="45%"></img> <img src="https://cloud.githubusercontent.com/assets/16852003/20928082/73b1e4f6-bbc4-11e6-8e3b-bb7cd73e8d87.png" width="45%"></img> 
</br>
Two leftmost images show the various LOOCV loss for varying lambda. The right image shows the fitted fourth degree polynomial with three different lambda values (0.0001....) being the best.
</br>
<img src="https://cloud.githubusercontent.com/assets/16852003/20928080/73a4c744-bbc4-11e6-8b17-a3f431f8993b.png" width="30%"></img> <img src="https://cloud.githubusercontent.com/assets/16852003/20928081/73b17c50-bbc4-11e6-9289-4103762241d7.png" width="30%"></img> <img src="https://cloud.githubusercontent.com/assets/16852003/20928083/73b26462-bbc4-11e6-8a3c-ea6215cbb9f5.png" width="30%"></img> 
